{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d963ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available conditions: ['faulty_bearing', 'healthy', 'misalignment', 'system_misalignment']\n",
      "Available frequencies: ['10hz', '20hz', '30hz', '40hz']\n",
      "Available loads: ['no_load', 'under_load']\n",
      "Total files: 134\n"
     ]
    }
   ],
   "source": [
    "# Setup Python path and imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# ML toolbox imports\n",
    "from ml_toolbox.data_loader import DatasetManager, DataLoader\n",
    "\n",
    "# Initialize dataset manager\n",
    "dataset_path = project_root / \"data_set\"\n",
    "dm = DatasetManager(dataset_path)\n",
    "\n",
    "# Initialize data loader \n",
    "data_loader = DataLoader(dataset_path)\n",
    "\n",
    "# Get dataset index and statistics\n",
    "index = dm.get_index()\n",
    "stats = dm.get_statistics()\n",
    "\n",
    "print(f\"Available conditions: {index['conditions']}\")\n",
    "print(f\"Available frequencies: {index['frequencies']}\")\n",
    "print(f\"Available loads: {index['loads']}\")\n",
    "print(f\"Total files: {stats['total_files']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319acfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Configuration:\n",
      "  Frequencies: ['20hz', '30hz']\n",
      "  Load condition: no load\n",
      "  Max windows per class: 50\n",
      "  Window length: 2048 samples\n",
      "  Total expected windows: ~400 (4 classes)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Import the new analysis modules\n",
    "from ml_toolbox.analysis import (\n",
    "    run_comprehensive_frequency_analysis,\n",
    "    plot_permuted_importance_comparison, \n",
    "    compare_top_features_across_frequencies\n",
    ")\n",
    "\n",
    "# Define frequencies to analyze\n",
    "frequencies_to_analyze = [\"20hz\", \"30hz\"]\n",
    "max_windows_per_class = 50\n",
    "window_length = 2048\n",
    "\n",
    "print(f\"Analysis Configuration:\")\n",
    "print(f\"  Frequencies: {frequencies_to_analyze}\")\n",
    "print(f\"  Load condition: no load\")\n",
    "print(f\"  Max windows per class: {max_windows_per_class}\")\n",
    "print(f\"  Window length: {window_length} samples\")\n",
    "print(f\"  Total expected windows: ~{max_windows_per_class * len(frequencies_to_analyze) * 4} (4 classes)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f43cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.data_loader:Loading 7 files with 1 workers\n",
      "INFO:ml_toolbox.data_loader.data_loader:Successfully loaded 7 files\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'faulty_bearing': extracted 50 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'misalignment': extracted 50 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'system_misalignment': extracted 50 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 0/150 windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive CV analysis for frequencies: ['20hz', '30hz']\n",
      "Load condition: under_load\n",
      "Max windows per class: 50\n",
      "Excel export enabled - output directory: test_output\n",
      "============================================================\n",
      "Loading 20hz under_load data...\n",
      "Loaded 7 current sensor files for 20hz\n",
      "Created 150 windows for 20hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 100/150 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Extracted 112 features from 150 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Signal features: 110\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Categorical features: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 112 features for 20hz\n",
      "Evaluating model for 20hz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.data_loader:Loading 7 files with 1 workers\n",
      "INFO:ml_toolbox.data_loader.data_loader:Successfully loaded 7 files\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'faulty_bearing': extracted 50 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'misalignment': extracted 50 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'system_misalignment': extracted 50 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 0/150 windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20hz - Mean CV Accuracy: 0.987 ± 0.016\n",
      "20hz CV analysis completed\n",
      "Loading 30hz under_load data...\n",
      "Loaded 7 current sensor files for 30hz\n",
      "Created 150 windows for 30hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 100/150 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Extracted 112 features from 150 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Signal features: 110\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Categorical features: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 112 features for 30hz\n",
      "Evaluating model for 30hz...\n",
      "30hz - Mean CV Accuracy: 1.000 ± 0.000\n",
      "30hz CV analysis completed\n",
      "CV results written to Excel: test_output/cv_results_under_load.xlsx\n",
      "Sheets created: CV_Summary, CV_Scores_Detail, Label_Distribution, Analysis_Info\n",
      "============================================================\n",
      "CV analysis completed for 2 frequencies\n",
      "CV analysis completed. For feature importance analysis, use run_comprehensive_shap_analysis instead.\n"
     ]
    }
   ],
   "source": [
    "# Run CV analysis across all frequencies with configurable window count\n",
    "cv_results = run_comprehensive_frequency_analysis(\n",
    "    data_loader, \n",
    "    frequencies_to_analyze, \n",
    "    load=\"under_load\",\n",
    "    max_windows_per_class=max_windows_per_class,\n",
    "    window_length=window_length,\n",
    "    export_to_excel=True,\n",
    "    output_dir=\"test_output\"\n",
    ")\n",
    "\n",
    "# For feature importance analysis, we'll use the new SHAP analysis instead\n",
    "print(\"CV analysis completed. For feature importance analysis, use run_comprehensive_shap_analysis instead.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb3775c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'analyze_frequency_performance_trends' from 'ml_toolbox.analysis' (d:\\code\\ml\\health-asyn-ml\\ml_toolbox\\analysis\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Display comprehensive results\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_toolbox\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manalysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      3\u001b[39m     plot_cv_results_comparison, \n\u001b[32m      4\u001b[39m     create_performance_summary,\n\u001b[32m      5\u001b[39m     analyze_frequency_performance_trends\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 1. Performance Summary Table\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPERFORMANCE SUMMARY ACROSS FREQUENCIES\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'analyze_frequency_performance_trends' from 'ml_toolbox.analysis' (d:\\code\\ml\\health-asyn-ml\\ml_toolbox\\analysis\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# Display comprehensive results\n",
    "from ml_toolbox.analysis import (\n",
    "    plot_cv_results_comparison, \n",
    "    create_performance_summary,\n",
    "    analyze_frequency_performance_trends\n",
    ")\n",
    "\n",
    "# 1. Performance Summary Table\n",
    "print(\"PERFORMANCE SUMMARY ACROSS FREQUENCIES\")\n",
    "print(\"=\" * 60)\n",
    "performance_summary = create_performance_summary(cv_results)\n",
    "print(performance_summary.to_string(index=False))\n",
    "\n",
    "# 2. Plot comprehensive CV results comparison\n",
    "print(\"\\nCOMPREHENSIVE CROSS-VALIDATION ANALYSIS\")\n",
    "plot_cv_results_comparison(cv_results)\n",
    "\n",
    "# 3. Analyze performance trends\n",
    "print(\"\\nFREQUENCY PERFORMANCE TRENDS\")\n",
    "analyze_frequency_performance_trends(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved CV Scores Visualization\n",
    "from ml_toolbox.analysis import plot_cv_scores_by_fold\n",
    "\n",
    "print(\"DETAILED CV SCORES BY FOLD FOR EACH FREQUENCY\")\n",
    "print(\"=\" * 60)\n",
    "plot_cv_scores_by_fold(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis has been moved to SHAP analysis\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"📝 NOTE: Feature importance analysis has been moved to a dedicated SHAP analysis module.\")\n",
    "print(\"   For feature importance analysis, use the new run_comprehensive_shap_analysis function:\")\n",
    "print()\n",
    "print(\"   Example:\")\n",
    "print(\"   from ml_toolbox.analysis import shap_analysis\")\n",
    "print(\"   oob_results, shap_results = shap_analysis.run_comprehensive_shap_analysis(\")\n",
    "print(\"       data_loader, frequencies_to_analyze, load='under_load',\")\n",
    "print(\"       max_windows_per_class=max_windows_per_class,\")\n",
    "print(\"       window_length=window_length, export_to_excel=True)\")\n",
    "print()\n",
    "print(\"   This provides both OOB (Random Forest) and SHAP importance analysis\")\n",
    "print(\"   with comprehensive visualizations and Excel export.\")\n",
    "print()\n",
    "print(\"🎯 run_comprehensive_frequency_analysis now focuses only on CV performance analysis\")\n",
    "print(\"   and returns only cv_results (not importance_results)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
