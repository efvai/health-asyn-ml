{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d963ae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available conditions: ['faulty_bearing', 'healthy', 'misalignment', 'system_misalignment']\n",
      "Available frequencies: ['10hz', '20hz', '30hz', '40hz']\n",
      "Available loads: ['no_load', 'under_load']\n",
      "Total files: 134\n"
     ]
    }
   ],
   "source": [
    "# Setup Python path and imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to Python path\n",
    "project_root = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# ML toolbox imports\n",
    "from ml_toolbox.data_loader import DatasetManager, DataLoader\n",
    "\n",
    "# Initialize dataset manager\n",
    "dataset_path = project_root / \"data_set\"\n",
    "dm = DatasetManager(dataset_path)\n",
    "\n",
    "# Initialize data loader \n",
    "data_loader = DataLoader(dataset_path)\n",
    "\n",
    "# Get dataset index and statistics\n",
    "index = dm.get_index()\n",
    "stats = dm.get_statistics()\n",
    "\n",
    "print(f\"Available conditions: {index['conditions']}\")\n",
    "print(f\"Available frequencies: {index['frequencies']}\")\n",
    "print(f\"Available loads: {index['loads']}\")\n",
    "print(f\"Total files: {stats['total_files']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319acfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Configuration:\n",
      "  Frequencies: ['10hz', '20hz', '30hz', '40hz']\n",
      "  Load condition: no load\n",
      "  Max windows per class: 40\n",
      "  Window length: 2048 samples\n",
      "  Total expected windows: ~640 (4 classes)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from ml_toolbox.analysis import run_comprehensive_frequency_analysis\n",
    "\n",
    "# Define frequencies to analyze\n",
    "frequencies_to_analyze = [\"10hz\", \"20hz\", \"30hz\", \"40hz\"]\n",
    "max_windows_per_class = 40  \n",
    "window_length = 2048 # 10Khz sampling, ~0.2s window\n",
    "\n",
    "print(f\"Analysis Configuration:\")\n",
    "print(f\"  Frequencies: {frequencies_to_analyze}\")\n",
    "print(f\"  Load condition: no load\")\n",
    "print(f\"  Max windows per class: {max_windows_per_class}\")\n",
    "print(f\"  Window length: {window_length} samples\")\n",
    "print(f\"  Total expected windows: ~{max_windows_per_class * len(frequencies_to_analyze) * 4} (4 classes)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f43cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.data_loader:Loading 12 files with 1 workers\n",
      "INFO:ml_toolbox.data_loader.data_loader:Successfully loaded 12 files\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'faulty_bearing': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'healthy': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'system_misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 0/160 windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive CV analysis for frequencies: ['10hz', '20hz', '30hz', '40hz']\n",
      "Load condition: no load\n",
      "Max windows per class: 40\n",
      "Excel export enabled - output directory: test_output\n",
      "============================================================\n",
      "Loading 10hz no load data...\n",
      "Loaded 12 current sensor files for 10hz\n",
      "Created 160 windows for 10hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 100/160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Extracted 112 features from 160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Signal features: 110\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Categorical features: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 112 features for 10hz\n",
      "Evaluating model for 10hz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.data_loader:Loading 12 files with 1 workers\n",
      "INFO:ml_toolbox.data_loader.data_loader:Successfully loaded 12 files\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'faulty_bearing': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'healthy': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'system_misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 0/160 windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10hz - Mean CV Accuracy: 0.956 ± 0.032\n",
      "10hz CV analysis completed\n",
      "Loading 20hz no load data...\n",
      "Loaded 12 current sensor files for 20hz\n",
      "Created 160 windows for 20hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 100/160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Extracted 112 features from 160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Signal features: 110\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Categorical features: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 112 features for 20hz\n",
      "Evaluating model for 20hz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.data_loader:Loading 12 files with 1 workers\n",
      "INFO:ml_toolbox.data_loader.data_loader:Successfully loaded 12 files\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'faulty_bearing': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'healthy': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'system_misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 0/160 windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20hz - Mean CV Accuracy: 0.931 ± 0.067\n",
      "20hz CV analysis completed\n",
      "Loading 30hz no load data...\n",
      "Loaded 12 current sensor files for 30hz\n",
      "Created 160 windows for 30hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 100/160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Extracted 112 features from 160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Signal features: 110\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Categorical features: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 112 features for 30hz\n",
      "Evaluating model for 30hz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.data_loader:Loading 11 files with 1 workers\n",
      "INFO:ml_toolbox.data_loader.data_loader:Successfully loaded 11 files\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'faulty_bearing': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'healthy': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'system_misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 0/160 windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30hz - Mean CV Accuracy: 0.963 ± 0.023\n",
      "30hz CV analysis completed\n",
      "Loading 40hz no load data...\n",
      "Loaded 11 current sensor files for 40hz\n",
      "Created 160 windows for 40hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 100/160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Extracted 112 features from 160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Signal features: 110\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Categorical features: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 112 features for 40hz\n",
      "Evaluating model for 40hz...\n",
      "40hz - Mean CV Accuracy: 0.906 ± 0.044\n",
      "40hz CV analysis completed\n",
      "CV results written to Excel: test_output/cv_results_no_load.xlsx\n",
      "Sheets created: CV_Summary, CV_Scores_Detail, Label_Distribution, Analysis_Info\n",
      "============================================================\n",
      "CV analysis completed for 4 frequencies\n"
     ]
    }
   ],
   "source": [
    "# Run CV analysis across all frequencies\n",
    "cv_results = run_comprehensive_frequency_analysis(\n",
    "    data_loader, \n",
    "    frequencies_to_analyze, \n",
    "    load=\"no load\",\n",
    "    max_windows_per_class=max_windows_per_class,\n",
    "    window_length=window_length,\n",
    "    export_to_excel=True,\n",
    "    output_dir=\"test_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d9238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.data_loader:Loading 12 files with 1 workers\n",
      "INFO:ml_toolbox.data_loader.data_loader:Successfully loaded 12 files\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'faulty_bearing': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'healthy': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.windowing:Class 'system_misalignment': extracted 40 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 0/160 windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting comprehensive SHAP analysis for frequencies: ['10hz', '20hz', '30hz', '40hz']\n",
      "Load condition: no load\n",
      "Max windows per class: 40\n",
      "CV folds: 5\n",
      "Per-class analysis: Enabled\n",
      "Excel export enabled - output directory: test_output\n",
      "============================================================\n",
      "Loading 10hz no load data...\n",
      "Loaded 12 current sensor files for 10hz\n",
      "Created 160 windows for 10hz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ml_toolbox.data_loader.feature_extraction:Processed 100/160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:Extracted 112 features from 160 windows\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Signal features: 110\n",
      "INFO:ml_toolbox.data_loader.feature_extraction:  - Categorical features: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 112 features for 10hz\n",
      "Computing feature importance for 10hz...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_toolbox\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01manalysis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feature_analysis\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Run SHAP analysis for all frequencies with Excel export\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m oob_results, shap_results = \u001b[43mshap_analysis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_comprehensive_shap_analysis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrequencies_to_analyze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mno load\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_windows_per_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_windows_per_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow_overlap\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexport_to_excel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest_output\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\ml_toolbox\\analysis\\shap_analysis.py:965\u001b[39m, in \u001b[36mrun_comprehensive_shap_analysis\u001b[39m\u001b[34m(data_loader, frequencies, load, max_windows_per_class, window_length, window_overlap, export_to_excel, output_dir, include_per_class, cv_folds)\u001b[39m\n\u001b[32m    959\u001b[39m features, labels, feature_names, metadata = extract_features_for_frequency(\n\u001b[32m    960\u001b[39m     data_loader, freq, load, max_windows_per_class=max_windows_per_class, \n\u001b[32m    961\u001b[39m     window_size=window_length, overlap_ratio=window_overlap\n\u001b[32m    962\u001b[39m )\n\u001b[32m    964\u001b[39m \u001b[38;5;66;03m# Analyze OOB importance\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m965\u001b[39m oob_result = \u001b[43manalyze_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    966\u001b[39m oob_results[freq] = oob_result\n\u001b[32m    968\u001b[39m \u001b[38;5;66;03m# Analyze overall SHAP importance\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\ml_toolbox\\analysis\\feature_analysis.py:190\u001b[39m, in \u001b[36manalyze_feature_importance\u001b[39m\u001b[34m(features, labels, feature_names, frequency, cv_folds)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mComputing feature importance for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfrequency\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# Get CV feature importance\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m cv_feature_importances = \u001b[43mget_feature_importance_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv_folds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Calculate statistics\u001b[39;00m\n\u001b[32m    193\u001b[39m mean_importance = np.mean(cv_feature_importances, axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\ml_toolbox\\analysis\\feature_analysis.py:165\u001b[39m, in \u001b[36mget_feature_importance_cv\u001b[39m\u001b[34m(X, y, cv_folds)\u001b[39m\n\u001b[32m    162\u001b[39m     model.fit(X_train_scaled, y_train_fold)\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Calculate permutation importance on validation set\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     perm_importance = \u001b[43m_calculate_permutation_feature_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     feature_importances.append(perm_importance)\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.array(feature_importances)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\ml_toolbox\\analysis\\feature_analysis.py:89\u001b[39m, in \u001b[36m_calculate_permutation_feature_importance\u001b[39m\u001b[34m(model, X_val, y_val)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minspection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# Use sklearn's permutation importance on validation set\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m result = \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Extract the mean importances from the result\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.array(result.importances_mean)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\venv\\Lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:288\u001b[39m, in \u001b[36mpermutation_importance\u001b[39m\u001b[34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[39m\n\u001b[32m    285\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m    286\u001b[39m baseline_score = _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m scores = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calculate_permutation_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    305\u001b[39m         name: _create_importances_bunch(\n\u001b[32m    306\u001b[39m             baseline_score[name],\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_score\n\u001b[32m    311\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\code\\ml\\health-asyn-ml\\venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run SHAP analysis across all frequencies\n",
    "from ml_toolbox.analysis import shap_analysis\n",
    "from ml_toolbox.analysis import feature_analysis\n",
    "\n",
    "# Run SHAP analysis for all frequencies with Excel export\n",
    "oob_results, shap_results, shap_per_class_results = shap_analysis.run_comprehensive_shap_analysis(\n",
    "    data_loader, \n",
    "    frequencies_to_analyze, \n",
    "    load=\"no load\",\n",
    "    max_windows_per_class=max_windows_per_class,\n",
    "    window_length=window_length,\n",
    "    window_overlap=0.5,\n",
    "    export_to_excel=True,\n",
    "    output_dir=\"test_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive results\n",
    "from ml_toolbox.analysis import (\n",
    "    plot_cv_results_comparison, \n",
    "    create_performance_summary\n",
    ")\n",
    "\n",
    "# 1. Performance Summary Table\n",
    "print(\"PERFORMANCE SUMMARY ACROSS FREQUENCIES\")\n",
    "print(\"=\" * 60)\n",
    "performance_summary = create_performance_summary(cv_results)\n",
    "print(performance_summary.to_string(index=False))\n",
    "\n",
    "# 2. Plot comprehensive CV results comparison\n",
    "print(\"\\nCROSS-VALIDATION ANALYSIS\")\n",
    "plot_cv_results_comparison(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_toolbox.analysis import plot_cv_scores_by_fold\n",
    "\n",
    "print(\"CV SCORES BY FOLD FOR EACH FREQUENCY\")\n",
    "print(\"=\" * 60)\n",
    "plot_cv_scores_by_fold(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd3431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis results from SHAP\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Show top SHAP features for each frequency\n",
    "print(\"\\nTOP 10 SHAP FEATURES BY FREQUENCY:\")\n",
    "for freq in frequencies_to_analyze:\n",
    "    if freq in shap_results:\n",
    "        print(f\"\\n{freq.upper()}:\")\n",
    "        top_10 = shap_results[freq].head(10)\n",
    "        for i, (_, row) in enumerate(top_10.iterrows(), 1):\n",
    "            print(f\"  {i:2d}. {row['Feature']:<25} | SHAP: {row['Mean_SHAP_Importance']:.4f} ± {row['Std_SHAP_Importance']:.4f}\")\n",
    "\n",
    "# 2. Show top PM features for comparison\n",
    "print(f\"\\nTOP 10 PM FEATURES BY FREQUENCY:\")\n",
    "for freq in frequencies_to_analyze:\n",
    "    if freq in oob_results:\n",
    "        print(f\"\\n{freq.upper()}:\")\n",
    "        top_10 = oob_results[freq].head(10)\n",
    "        for i, (_, row) in enumerate(top_10.iterrows(), 1):\n",
    "            print(f\"  {i:2d}. {row['Feature']:<25} | PM: {row['Mean_Importance']:.4f} ± {row['Std_Importance']:.4f}\")\n",
    "\n",
    "# 3. Plot SHAP importance comparison\n",
    "print(f\"\\nSHAP FEATURE IMPORTANCE VISUALIZATION\")\n",
    "shap_analysis.plot_shap_importance_comparison(shap_results, top_n=15)\n",
    "\n",
    "# Plot PM importance comparison \n",
    "print(f\"\\nPM FEATURE IMPORTANCE VISUALIZATION\")\n",
    "feature_analysis.plot_feature_importance_comparison(oob_results, top_n=15)\n",
    "\n",
    "# 4. Compare PM vs SHAP for one frequency as example\n",
    "if \"20hz\" in oob_results and \"20hz\" in shap_results:\n",
    "    print(f\"\\nPM vs SHAP COMPARISON FOR 20HZ:\")\n",
    "    comparison_example = shap_analysis.compare_oob_vs_shap_importance(oob_results[\"20hz\"], shap_results[\"20hz\"])\n",
    "    correlation = comparison_example['OOB_Normalized'].corr(comparison_example['SHAP_Normalized'])\n",
    "    print(f\"   Importance correlation: {correlation:.3f}\")\n",
    "    print(f\"   Mean agreement score: {comparison_example['Agreement_Score'].mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
